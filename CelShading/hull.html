<!--  
Identical to LightingWithTexture but uses the Three.js OBJ file loader.
It is not in the main three.js file so you may need to edit your path to it,
see the bottom of this file.  The shader code is unchanged.
Edit the filenames at the top of the .js file to try different images or
models.  You will also need the updated Camera.js class, which includes a function
for the key controls.
-->		

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<title>Texture with lighting</title>
</head>

<body> 
	<canvas id="theCanvas" width="1024" height="1024">
    Please use a browser that supports "canvas"
    </canvas>

<p>
<li>SPACE - pause rotation
<li>x - rotate about x axis
<li>y - rotate about y axis
<li>z - rotate about z axis
<p>
Camera controls:
<ul style="list-style:none;">
<li>m - Swap to Sobel outline
<li>n - Swap to hull outline
<li>w, a, s, d - move forward, left, back, right
<li>r, f - move up, down
<li>i, j, k, l - look up, left, down, right
<li>I, J, K, L - orbit down, right, up, left
<li>O - face origin
<li>p - put camera at origin
<li>W - decrease fov
<li>S - increase fov
<li>1, 2, 3, 4, 5 - change texture parameters
</ul>


<script id="vertexLightingShader" type="x-shader/x-vertex">
precision mediump float;

uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;
uniform mat3 normalMatrix;
uniform vec4 lightPosition;

attribute vec4 a_Position;
attribute vec3 a_Normal;
attribute vec2 a_TexCoord;

varying vec3 fL;
varying vec3 fN;
varying vec3 fV;
varying vec2 fTexCoord;

void main()
{
  // convert position to eye coords
  vec4 positionEye = view * model * a_Position;

  // convert light position to eye coords
  vec4 lightEye = view * lightPosition;

  // vector to light
  fL = (lightEye - positionEye).xyz;

  // transform normal matrix into eye coords
  fN = normalMatrix * a_Normal;

  // vector from vertex position toward view point
  fV = normalize(-(positionEye).xyz);

  fTexCoord = a_TexCoord;

  gl_Position = projection * view * model * a_Position;
}
</script>


<script id="fragmentLightingShader" type="x-shader/x-fragment">
precision mediump float;
// Kept a lot in here for experimentation with dif shading methods
// I personally like experimenting with speculars and toon shading
uniform mat3 materialProperties;
uniform mat3 lightProperties;
uniform float shininess;
uniform sampler2D sampler;

varying vec3 fL;
varying vec3 fN;
varying vec3 fV;
varying vec2 fTexCoord;

void main() 
{
  // normalize after interpolating
  vec3 N = normalize(fN);
  vec3 L = normalize(fL);
  vec3 V = normalize(fV);

  // Calculate what is lit and whats not by what is facing away from the light
  // float NdotL = 1.0 + clamp(floor(dot(N, L)), -0.55, 0.0);
  float NdotL = smoothstep(-1.4, 0.5, floor(dot(N, L)));

  // reflected vector
  vec3 R = reflect(-L, N);

  // get the columns out of the light and material properties.  We keep the surface
  // properties separate, so we can mess with them using the sampled texture value
  vec4 ambientSurface = vec4(materialProperties[0], 1.0);
  vec4 diffuseSurface = vec4(materialProperties[1], 1.0);
  vec4 specularSurface = vec4(materialProperties[2], 1.0);

  vec4 ambientLight = vec4(lightProperties[0], 1.0);
  vec4 diffuseLight = vec4(lightProperties[1], 1.0);
  vec4 specularLight = vec4(lightProperties[2], 1.0);

  // sample from the texture at interpolated texture coordinate
  vec4 color = texture2D(sampler, fTexCoord);

  // (1) use the value directly as the surface color and ignore the material properties
  ambientSurface = color;
  diffuseSurface = color;

  // (2) modulate intensity of surface color (or of any component)
  //float m = (color.r + color.g + color.b) / 3.0;
  //ambientSurface *= m;
  //diffuseSurface *= m;
  //specularSurface *= m;

  // (3) blend texture using its alpha value (try this with "steve.png")
  //float m = color.a;
  //ambientSurface = (1.0 - m) * ambientSurface + m * color;
  //diffuseSurface = (1.0 - m) * diffuseSurface + m * color;
  //specularSurface = (1.0 - m) * specularSurface + m * color;

  // lighting factors as usual

  // Lambert's law, clamp negative values to zero
  float diffuseFactor = max(0.0, dot(L, N));

  // specular factor from Phong reflection model
  float specularFactor = pow(max(0.0, dot(V, R)), shininess);

  // add the components together, note that vec4 * vec4 is componentwise multiplication,
  // not a dot product
  vec4 ambient = ambientLight * ambientSurface;
  vec4 diffuse = diffuseFactor * diffuseLight * diffuseSurface;
  vec4 specular = specularFactor * specularLight * specularSurface;

  // Multiply normal texture by NdotL for simple shading

  // Phong model for comparison
  //gl_FragColor = ambient + specular + diffuse;

  // Simple texture shading for toon shading
  // NOTE: To get really accurate shading, you probably need to create the
  // normals by hand.
  gl_FragColor = color * NdotL;

  // Plain yellowish color in toon shading (shows inverse hull problem well)
  //gl_FragColor = vec4(1.0, 0.7, 0.0, 1.0) * NdotL;
  gl_FragColor.a = 1.0;
}
</script>

<script id="vertexTextureShader" type="x-shader/x-vertex">
attribute vec4 a_Position;
attribute vec2 a_TexCoord;
varying vec2 fTexCoord;
void main() 
{
  // pass through so the value gets interpolated 
  fTexCoord = a_TexCoord;
  gl_Position = a_Position;
}
</script>

<script id="fragmentTextureShader" type="x-shader/x-fragment">
precision mediump float;
uniform sampler2D sampler;
varying vec2 fTexCoord;
void main() 
{
  // sample from the texture at the interpolated texture coordinate,
  // use the texture's alpha to blend with given color
  vec4 texColor = texture2D(sampler, fTexCoord);
  gl_FragColor = texColor;
}
</script>


<script id="vertexDbShader" type="x-shader/x-vertex">
precision mediump float;
attribute vec4 a_Position;
uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;
varying float depth;
 
void main(){
    vec4 pos = projection * view * model * a_Position;
    // Get Z buffer depth
    // So, 1.0 is supposed to be the near and 999.0 the far of the scene.
    // I could have actually used uniforms and used the actual depth of my
    // scene, but I left it as is for demo purposes, just because I did not want 
    // to recalculate a depth threshold for an optimal outline.
    depth = (-pos.z-1.0) / 999.0;
    gl_Position = pos;
}
</script>

<script id="fragmentDbShader" type="x-shader/x-fragment">
precision mediump float;
varying float depth;
void main(){

   //Taken from 
   //https://kbalentertainment.wordpress.com/2013/11/27/
   //tutorial-cel-shading-with-libgdx-and-opengl-es-2-0-using-post-processing/

    vec4 bit_shift = vec4(256.0*256.0*256.0, 256.0*256.0, 256.0, 1.0);
    vec4 bit_mask  = vec4(0.0, 1.0/256.0, 1.0/256.0, 1.0/256.0);
    vec4 res = fract(depth * bit_shift);
    res -= res.xxyz * bit_mask;
    gl_FragColor = res;
}
</script>

<script id="outlineVertexShader" type="x-shader/x-vertex">
precision mediump float;

attribute vec4 a_Position;
attribute vec2 a_TexCoord0;

uniform vec2 size;

varying vec2 texCoords0;
varying vec2 texCoords1;
varying vec2 texCoords2;
varying vec2 texCoords3;
varying vec2 texCoords4;
varying vec2 texCoords5;
varying vec2 texCoords6;
varying vec2 texCoords7;


void main(){

   // So, this was originally another persons code for implementing a different
   // image processing kernel sort of, I originally changed it a bit, and since
   // implementing the sobel operator have changed it significantly

   // Idea: Sample 6 points for each kernel, those horizontal to the original
   // point and those vertical to it. Divide by size for correct pixel size
    texCoords0 = a_TexCoord0 + vec2(-1.0 / size.x, 1.0 / size.y);
    texCoords1 = a_TexCoord0 + vec2(-1.0 / size.x, 0.0);
    texCoords2 = a_TexCoord0 + vec2(-1.0 / size.x, -1.0 / size.y);
    texCoords3 = a_TexCoord0 + vec2(1.0 / size.x, 1.0 / size.y);
    texCoords4 = a_TexCoord0 + vec2(1.0 / size.x, 0.0);
    texCoords5 = a_TexCoord0 + vec2(1.0 / size.x, -1.0 / size.y);
    texCoords6 = a_TexCoord0 + vec2(0.0, 1.0 / size.y);
    texCoords7 = a_TexCoord0 + vec2(0.0, -1.0 / size.y);

    
    gl_Position = a_Position;

}
</script>

<script id="outlineFragShader" type="x-shader/x-fragment">
precision mediump float;
 
uniform sampler2D depthTexture;
varying vec2 texCoords0;
varying vec2 texCoords1;
varying vec2 texCoords2;
varying vec2 texCoords3;
varying vec2 texCoords4;
varying vec2 texCoords5;
varying vec2 texCoords6;
varying vec2 texCoords7;


//Taken from same place
float unpack_depth(vec4 rgba_depth){
    vec4 bit_shift = vec4(1.0/(256.0*256.0*256.0), 1.0/(256.0*256.0), 1.0/256.0, 1.0);
    float depth = dot(rgba_depth, bit_shift);
    return depth;
}


void main(){

   // NOTE: There are some jagged lines with rotation, what is done to combat
   // this is usually another kernel to blur. You can also use a smoothing
   // kernel but I did not find too much more information on this. Lastly, 
   // you can use a larger sobel kernel, but according to Intel, that is
   // wasteful and you should just use a different shader with more kernels over
   // a bigger kernel.

   // Multiply the points by the vertical kernel
    float depthh =
        abs(unpack_depth(-1.0 * texture2D(depthTexture, texCoords0))
    + unpack_depth(-2.0 * texture2D(depthTexture, texCoords1))
    + unpack_depth(-1.0 * texture2D(depthTexture, texCoords2))
    + unpack_depth(1.0 * texture2D(depthTexture, texCoords3))
    + unpack_depth(2.0 * texture2D(depthTexture, texCoords4))
    + unpack_depth(1.0 * texture2D(depthTexture, texCoords5)));

   // And by horizontal
   float depthv = 
           abs(unpack_depth(-1.0 * texture2D(depthTexture, texCoords0))
    + unpack_depth(-2.0 * texture2D(depthTexture, texCoords6))
    + unpack_depth(-1.0 * texture2D(depthTexture, texCoords3))
    + unpack_depth(1.0 * texture2D(depthTexture, texCoords2))
    + unpack_depth(2.0 * texture2D(depthTexture, texCoords7))
    + unpack_depth(1.0 * texture2D(depthTexture, texCoords5)));

   // Merge by using the formula for the operator
   float depth = sqrt(pow(depthh, 2.0) + pow(depthv, 2.0));
   // Check threshold of how detailed you want edges
    if(depth > 0.0004){
    gl_FragColor = vec4(0.0,0.0,0.0,1.0);
    } else{
    gl_FragColor = vec4(1.0,1.0,1.0,0.0);
    }
}
</script>

<script id="invertVertexShader" type="x-shader/x-vertex">
precision mediump float;

uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;
uniform mat3 normalMatrix;

attribute vec4 a_Position;
attribute vec3 a_Normal;
attribute vec2 a_TexCoord;

varying vec3 fN;

void main()
{
  // transform normal matrix into eye coords
  fN = normalMatrix *   a_Normal;
  gl_Position = projection * view * model * a_Position + (vec4(fN, 1.0) * 0.04);
}
</script>

<script id="invertFragShader" type="x-shader/x-fragment">
void main() 
{
  gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);
}
</script>





		<script src="../teal_book/webgl-utils.js"></script>
		<script src="../teal_book/webgl-debug.js"></script>
		<script src="../teal_book/cuon-utils.js"></script>
		<script src="../teal_book/cuon-matrix.js"></script>
		<script src="Camera.js"></script>
		
		<!-- Use three.js if you have it locally, for easier debugging -->
		<script src="../threejs/three.js"></script>
		
		<!--  otherwise, load the minified version from the www -->
		<!--script src="http://threejs.org/build/three.min.js"></script-->
		
		<!-- the OBJ file loader is not included in the regular three.js file -->
		<script src="../threejs/OBJLoader.js"></script>
		
		<script src="hull.js"></script>
		<script>window.onload = main</script>
</body>
</html>
